{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dec7fe3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Laadige oma andmed\n",
    "df = pd.read_csv(\"df_pairs_final.csv\", sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "daf6c930",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: jellyfish in c:\\users\\kasutaja\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (1.2.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install jellyfish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "318c13d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from jellyfish import levenshtein_distance\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "# --- Tokeniseerimine ja mõõdikute arvutus ---\n",
    "def tokenize(text):\n",
    "    return set(text.lower().split())\n",
    "\n",
    "def calculate_all_metrics(row, column_name, target_col):\n",
    "    col_value = row[column_name]\n",
    "    final_value = row[target_col]\n",
    "\n",
    "    col_tokens = tokenize(col_value)\n",
    "    final_tokens = tokenize(final_value)\n",
    "    overlap = col_tokens.intersection(final_tokens)\n",
    "    token_overlap = len(overlap) / max(min(len(col_tokens), len(final_tokens)), 2)\n",
    "\n",
    "    dist = levenshtein_distance(col_value, final_value)\n",
    "    max_len = max(len(col_value), len(final_value))\n",
    "    levenshtein_score = 1 - dist / max_len if max_len > 0 else 1.0\n",
    "\n",
    "    full_match = 1 if col_value == final_value else 0\n",
    "\n",
    "    return pd.Series([token_overlap, levenshtein_score, full_match])\n",
    "\n",
    "def run_logistic_regression_component_model(df, columns, target_col):\n",
    "    for col in columns:\n",
    "        df[[f\"{col}_token_overlap\", f\"{col}_levenshtein\", f\"{col}_full_match\"]] = \\\n",
    "            df.apply(lambda row: calculate_all_metrics(row, col, target_col), axis=1)\n",
    "\n",
    "    y_true = df[\"label\"].astype(int)\n",
    "    thresholds = np.arange(0.0, 1.01, 0.01)\n",
    "    results = []\n",
    "\n",
    "    for col in columns:\n",
    "        feature_cols = [f\"{col}_token_overlap\", f\"{col}_levenshtein\", f\"{col}_full_match\"]\n",
    "        X = df[feature_cols]\n",
    "\n",
    "        model = LogisticRegression(penalty='l2', solver='liblinear', random_state=123)\n",
    "        model.fit(X, y_true)\n",
    "        proba = model.predict_proba(X)[:, 1]\n",
    "\n",
    "        best_f1 = 0\n",
    "        best_threshold = 0\n",
    "        best_precision = 0\n",
    "        best_recall = 0\n",
    "\n",
    "        for threshold in thresholds:\n",
    "            y_pred = (proba >= threshold).astype(int)\n",
    "            precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "                y_true, y_pred, average='binary', zero_division=0\n",
    "            )\n",
    "            if f1 > best_f1:\n",
    "                best_f1 = f1\n",
    "                best_threshold = threshold\n",
    "                best_precision = precision\n",
    "                best_recall = recall\n",
    "\n",
    "        results.append([\n",
    "            col,\n",
    "            round(best_threshold, 2),\n",
    "            round(best_precision, 4),\n",
    "            round(best_recall, 4),\n",
    "            round(best_f1, 4)\n",
    "        ])\n",
    "\n",
    "    return pd.DataFrame(results, columns=[\"Skeem\", \"Parim lävend\", \"Täpsus\", \"Saagis\", \"F1-skoor\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2008a01e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tulemused (põhiskeemid):\n",
      "      Skeem  Parim lävend  Täpsus  Saagis  F1-skoor\n",
      "       iso9          0.42  0.9561  0.8394    0.8940\n",
      "     dstu_a          0.43  0.9389  0.8108    0.8702\n",
      "       icao          0.45  0.9769  0.8647    0.9174\n",
      "     dstu_b          0.42  0.9362  0.8224    0.8756\n",
      "     gost_b          0.43  0.9653  0.8510    0.9046\n",
      "        bgn          0.47  0.9792  0.8616    0.9167\n",
      "rt_translit          0.42  0.9617  0.8448    0.8994\n",
      "        eki          0.43  0.9672  0.8459    0.9025\n",
      "   OS_ascii          0.46  0.9749  0.8757    0.9227\n"
     ]
    }
   ],
   "source": [
    "columns = [\"iso9\", \"dstu_a\", \"icao\", \"dstu_b\", \"gost_b\", \"bgn\", \"rt_translit\", \"eki\", \"OS_ascii\"]\n",
    "target_col = \"name_final\"\n",
    "\n",
    "df_results = run_logistic_regression_component_model(df, columns, target_col)\n",
    "print(\"Tulemused (põhiskeemid):\")\n",
    "print(df_results.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b1d979af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tulemused (ASCII skeemid):\n",
      "            Skeem  Parim lävend  Täpsus  Saagis  F1-skoor\n",
      "       iso9_ascii          0.41  0.9614  0.8548    0.9050\n",
      "     dstu_a_ascii          0.46  0.9574  0.8123    0.8789\n",
      "       icao_ascii          0.44  0.9767  0.8674    0.9188\n",
      "     dstu_b_ascii          0.43  0.9451  0.8187    0.8774\n",
      "     gost_b_ascii          0.45  0.9728  0.8474    0.9058\n",
      "        bgn_ascii          0.46  0.9791  0.8647    0.9183\n",
      "rt_translit_ascii          0.42  0.9650  0.8498    0.9037\n",
      "        eki_ascii          0.40  0.9618  0.8575    0.9067\n",
      "         OS_ascii          0.45  0.9755  0.8806    0.9256\n"
     ]
    }
   ],
   "source": [
    "ascii_columns = [\"iso9_ascii\", \"dstu_a_ascii\", \"icao_ascii\", \"dstu_b_ascii\", \"gost_b_ascii\", \"bgn_ascii\", \"rt_translit_ascii\", \"eki_ascii\", \"OS_ascii\"]\n",
    "target_col = \"name_ascii\"\n",
    "\n",
    "df_results_ascii = run_logistic_regression_component_model(df, ascii_columns, target_col)\n",
    "print(\"Tulemused (ASCII skeemid):\")\n",
    "print(df_results_ascii.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "514ca420",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !jupyter nbconvert --to html regression.ipynb --log-level=ERROR > nul 2>&1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
